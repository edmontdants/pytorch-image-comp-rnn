{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch-image-comp-using-rnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edmontdants/pytorch-image-comp-rnn/blob/master/Colab/pytorch_image_comp_using_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqnt2tf2ZWXg"
      },
      "source": [
        "!pip list -v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuG4876rjGvc"
      },
      "source": [
        "## Setup Colab Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLv0HL4DZm2e"
      },
      "source": [
        "#dont try to run any of these\n",
        "#!pip install torch==0.2.0\n",
        "#!pip install torch==1.0.1\n",
        "#!pip install torch==1.8.1\n",
        "#!pip install Pillow==4.3.0\n",
        "#!pip install Pillow==7.1.2\n",
        "#!pip install Pillow==8.2.0\n",
        "#pip install scipy==1.1.0\n",
        "#pip install scipy==1.4.1\n",
        "#pip install scipy==1.6.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuLzI6lOSOS1"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from imageio import imread, imsave\n",
        "#from scipy.misc import imread, imresize, imsave\n",
        "#from skimage import io, color, data\n",
        "#from PIL import Image\n",
        "\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import collections\n",
        "import zipfile\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.display import Image as DisplayImage\n",
        "from IPython.display import Javascript\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "\n",
        "INPUT_DIR = '/content/files'\n",
        "OUT_DIR = '/content/out'\n",
        "CKPT_DIR = '/content/checkpoint'\n",
        "\n",
        "_ = [os.makedirs(dir, exist_ok=True) for dir in (INPUT_DIR, OUT_DIR, CKPT_DIR)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xxyfFZQjRHE"
      },
      "source": [
        "## Clone Our Repo & Model Checkpoints in Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVAJbeRlYJXZ"
      },
      "source": [
        "!git clone https://github.com/edmontdants/pytorch-image-comp-rnn.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-j5BQHPQ9Bk"
      },
      "source": [
        "!wget -q --show-progress \"https://github.com/edmontdants/pytorch-image-comp-rnn/releases/download/1.0/encoder_epoch_00000066.pth\" -P '/content/checkpoint'\n",
        "!wget -q --show-progress \"https://github.com/edmontdants/pytorch-image-comp-rnn/releases/download/1.0/decoder_epoch_00000066.pth\" -P '/content/checkpoint'\n",
        "!wget -q --show-progress \"https://github.com/edmontdants/pytorch-image-comp-rnn/releases/download/1.0/binarizer_epoch_00000066.pth\" -P '/content/checkpoint'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEm79xPkSqs-"
      },
      "source": [
        "#!pip install torch==1.8.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8P2g6eVhDa6"
      },
      "source": [
        "## Enabling GPU and Run\n",
        "\n",
        "GPU should be enabled from this part. If the next cell prints a warning, do the following:\n",
        "- Navigate to `Edit â†’> Notebook Settings`\n",
        "- Select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "unless next cell well get an error torch because --cuda argument is given and the Encoding Process consumes more than 15 GBs of GPU Memory for just like 6 or 7 iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Nn4gUA7Pbxj",
        "outputId": "a6a6fe5a-9bac-473c-c1dd-11a31a56fa3a"
      },
      "source": [
        "if torch.cuda.is_available() is False:\n",
        "  print('WARNING: No GPU found. Compression/decompression will be slow!')\n",
        "else:\n",
        "  print(f'Found GPU {torch.cuda.get_device_name(0)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZSw1TCpS-T1"
      },
      "source": [
        "!python encoder.py --model checkpoint/encoder_epoch_00000066.pth --input example.png --cuda --output /content/files/example.npz --iterations 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQxvOUzCw-JL"
      },
      "source": [
        "#torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAMRraK7ToKU"
      },
      "source": [
        "!python decoder.py --model checkpoint/decoder_epoch_00000066.pth --input /content/files/example.npz --cuda --output /content/out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtaSCARlklFb"
      },
      "source": [
        "### Results can be found in 'out'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U62hap_KiIJj"
      },
      "source": [
        "# Show output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7DzgSOhiaxq"
      },
      "source": [
        "#def print_html(html):\n",
        "#    display(HTML(html + '<br/>'))\n",
        "\n",
        "#def make_cell_large():\n",
        "#    display(Javascript(\n",
        "#        '''google.colab.output.setIframeHeight(0, true, {maxHeight: 5192})'''))\n",
        "\n",
        "#make_cell_large()  # Larger output window.\n",
        "\n",
        "#for file in all_outputs:\n",
        "#    print_html('<hr/>')\n",
        "#    file_name, _ = os.path.splitext(file.output_path)\n",
        "#    original_size = original_sizes[os.path.basename(file_name).split('_compressed')[0]]\n",
        "#    print(f'Showing {file.output_path} | {file.num_bytes//1000} kB (compressed) | {file.bpp:.4f} bpp | Original: {original_size//1000} kB')\n",
        "#    display(Image.open(file.output_path))\n",
        "#    print_html('<hr/>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL3X1lvCiosz"
      },
      "source": [
        "You can compress new images by going back to the \"Prepare Images\" heading and selecting a different default image or upload your own for compression, then running the cells below in sequence. Note that each model cannot decompress the output generated by a different model, and you need to delete the contents of `/content/out` if you want to try a different model.\n",
        "\n",
        "Please open an issue if you encounter an error when running this demo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdIGKWByivX3"
      },
      "source": [
        "### Download compressed images\n",
        "\n",
        "Note: Files are losslessly saved as PNG for viewing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oKKyjCZiy2y"
      },
      "source": [
        "#if download_outputs is True:\n",
        "#    ZIP = '/content/RNNResidualGRU_compressed_images.zip'\n",
        "\n",
        "#    with zipfile.ZipFile(ZIP, 'w') as zf:\n",
        "#        for f in all_outputs:\n",
        "#            path_with_bpp = f.output_path.replace('.png', f'-{f.bpp:.3f}bpp.png')\n",
        "#            zf.write(f.output_path, os.path.basename(path_with_bpp))\n",
        "\n",
        "#    files.download(ZIP) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}